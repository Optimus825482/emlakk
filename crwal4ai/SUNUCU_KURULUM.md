# Crawler Sunucu Kurulum ve Sorun Giderme

## ğŸš¨ Crawler Ã‡alÄ±ÅŸmÄ±yor - Sorun Giderme AdÄ±mlarÄ±

### 1. Diagnostic Tool Ã‡alÄ±ÅŸtÄ±r

Sunucuya SSH ile baÄŸlan ve diagnostic tool'u Ã§alÄ±ÅŸtÄ±r:

```bash
cd /path/to/crwal4ai/admin_remix
python diagnostic.py
```

Bu tool ÅŸunlarÄ± kontrol eder:

- âœ… Python versiyonu
- âœ… Google Chrome kurulu mu
- âœ… Xvfb (virtual display) Ã§alÄ±ÅŸÄ±yor mu
- âœ… Python dependencies kurulu mu
- âœ… Database baÄŸlantÄ±sÄ± Ã§alÄ±ÅŸÄ±yor mu
- âœ… Dosya izinleri doÄŸru mu
- âœ… Crawler script syntax hatasÄ± var mÄ±

### 2. LoglarÄ± Kontrol Et

Crawler Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda 2 log dosyasÄ± oluÅŸur:

```bash
# STDOUT logu
cat /path/to/crwal4ai/admin_remix/crawler_debug.log

# STDERR logu (hatalar burada)
cat /path/to/crwal4ai/admin_remix/crawler_error.log
```

### 3. Manuel Test

Crawler'Ä± manuel olarak test et:

```bash
cd /path/to/crwal4ai/admin_remix
python sahibinden_uc_batch_supabase.py --categories konut_satilik --max-pages 1
```

EÄŸer hata alÄ±rsan, hatayÄ± not al ve dÃ¼zelt.

---

## ğŸ”§ YaygÄ±n Sorunlar ve Ã‡Ã¶zÃ¼mleri

### Sorun 1: Chrome BulunamadÄ±

**Hata:**

```
selenium.common.exceptions.WebDriverException: Message: unknown error: cannot find Chrome binary
```

**Ã‡Ã¶zÃ¼m:**

```bash
# Chrome kur
wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | gpg --dearmor -o /usr/share/keyrings/google-chrome.gpg
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome.gpg] http://dl.google.com/linux/chrome/deb/ stable main" > /etc/apt/sources.list.d/google-chrome.list
apt-get update
apt-get install -y google-chrome-stable

# Kontrol et
google-chrome --version
```

### Sorun 2: Display HatasÄ±

**Hata:**

```
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: exited abnormally
```

**Ã‡Ã¶zÃ¼m:**

```bash
# Xvfb kur
apt-get install -y xvfb

# Xvfb baÅŸlat
Xvfb :99 -screen 0 1920x1080x24 &

# DISPLAY deÄŸiÅŸkenini ayarla
export DISPLAY=:99

# Kontrol et
echo $DISPLAY
ps aux | grep Xvfb
```

### Sorun 3: Database BaÄŸlantÄ± HatasÄ±

**Hata:**

```
psycopg2.OperationalError: could not connect to server
```

**Ã‡Ã¶zÃ¼m:**

```bash
# .env dosyasÄ±nÄ± kontrol et
cat /path/to/crwal4ai/admin_remix/.env

# DATABASE_URL doÄŸru mu?
# DoÄŸru format:
# DATABASE_URL=postgres://postgres:518518Erkan@wgkosgwkg8o4wg4k8cgcw4og:5432/demir_db

# Database'e baÄŸlanabilir misin?
psql "postgres://postgres:518518Erkan@wgkosgwkg8o4wg4k8cgcw4og:5432/demir_db" -c "SELECT 1"
```

### Sorun 4: Python Dependencies Eksik

**Hata:**

```
ModuleNotFoundError: No module named 'undetected_chromedriver'
```

**Ã‡Ã¶zÃ¼m:**

```bash
cd /path/to/crwal4ai/admin_remix
pip install -r requirements.txt

# Veya tek tek:
pip install undetected-chromedriver selenium beautifulsoup4 psycopg2-binary flask python-dotenv
```

### Sorun 5: Dosya Ä°zin HatasÄ±

**Hata:**

```
PermissionError: [Errno 13] Permission denied: '/app/admin_remix/uc_chrome_profile'
```

**Ã‡Ã¶zÃ¼m:**

```bash
# Crawler klasÃ¶rÃ¼ne yazma izni ver
chmod -R 755 /path/to/crwal4ai/admin_remix
chown -R www-data:www-data /path/to/crwal4ai/admin_remix

# Veya Docker iÃ§inde:
chmod -R 777 /app/admin_remix/uc_chrome_profile
```

---

## ğŸ³ Docker Container Ä°Ã§inde Sorun Giderme

### Container'a Gir

```bash
# Container ID'yi bul
docker ps

# Container'a gir
docker exec -it <container_id> bash
```

### Diagnostic Tool Ã‡alÄ±ÅŸtÄ±r

```bash
cd /app/admin_remix
python diagnostic.py
```

### LoglarÄ± Ä°zle

```bash
# Flask app logu
docker logs -f <container_id>

# Crawler logu
docker exec -it <container_id> tail -f /app/admin_remix/crawler_debug.log
docker exec -it <container_id> tail -f /app/admin_remix/crawler_error.log
```

### Manuel Crawler Test

```bash
docker exec -it <container_id> bash
cd /app/admin_remix
export DISPLAY=:99
python sahibinden_uc_batch_supabase.py --categories konut_satilik --max-pages 1
```

---

## ğŸ“Š Mining Jobs Tablosunu Kontrol Et

Crawler job'larÄ± `mining_jobs` tablosunda saklanÄ±r:

```sql
-- Son 10 job'u gÃ¶ster
SELECT
    id,
    job_type,
    status,
    created_at,
    error
FROM mining_jobs
ORDER BY created_at DESC
LIMIT 10;

-- Failed job'larÄ±n hatalarÄ±nÄ± gÃ¶ster
SELECT
    id,
    created_at,
    error
FROM mining_jobs
WHERE status = 'failed'
ORDER BY created_at DESC
LIMIT 5;
```

---

## ğŸ”„ Crawler'Ä± Yeniden BaÅŸlat

### Docker Container'Ä± Yeniden BaÅŸlat

```bash
# Container'Ä± durdur
docker stop <container_id>

# Container'Ä± baÅŸlat
docker start <container_id>

# Veya yeniden build et
cd /path/to/crwal4ai
docker build -t crawler-app .
docker run -d -p 5001:5001 --name crawler crawler-app
```

### Coolify'da Yeniden Deploy

1. Coolify dashboard'a git
2. Crawler service'i bul
3. "Redeploy" butonuna tÄ±kla
4. LoglarÄ± izle

---

## ğŸ“ Ã–nemli Notlar

1. **Xvfb Mutlaka Ã‡alÄ±ÅŸmalÄ±**: Headless Chrome iÃ§in virtual display gerekli
2. **DISPLAY=:99**: Environment variable doÄŸru ayarlanmalÄ±
3. **Chrome Kurulu OlmalÄ±**: google-chrome-stable paketi kurulu olmalÄ±
4. **Database BaÄŸlantÄ±sÄ±**: Internal hostname kullan (wgkosgwkg8o4wg4k8cgcw4og:5432)
5. **Dosya Ä°zinleri**: Chrome profile klasÃ¶rÃ¼ne yazma izni olmalÄ±

---

## ğŸ†˜ Hala Ã‡alÄ±ÅŸmÄ±yor mu?

1. **Diagnostic tool Ã§Ä±ktÄ±sÄ±nÄ± kaydet**:

   ```bash
   python diagnostic.py > diagnostic_output.txt
   ```

2. **TÃ¼m loglarÄ± topla**:

   ```bash
   cat crawler_debug.log > all_logs.txt
   cat crawler_error.log >> all_logs.txt
   docker logs <container_id> >> all_logs.txt
   ```

3. **Database job'larÄ±nÄ± kontrol et**:

   ```sql
   SELECT * FROM mining_jobs ORDER BY created_at DESC LIMIT 5;
   ```

4. **Bu bilgileri Erkan'a gÃ¶nder** - sorun Ã§Ã¶zÃ¼lÃ¼r!

---

## âœ… BaÅŸarÄ±lÄ± Kurulum KontrolÃ¼

Crawler doÄŸru Ã§alÄ±ÅŸÄ±yorsa:

1. âœ… `python diagnostic.py` tÃ¼m kontrolleri geÃ§er
2. âœ… Manuel test baÅŸarÄ±lÄ± olur
3. âœ… `mining_jobs` tablosunda `status='completed'` gÃ¶rÃ¼nÃ¼r
4. âœ… `collected_listings` tablosuna yeni ilanlar eklenir
5. âœ… Admin panelde "Ä°ÅŸlem GÃ¼nlÃ¼ÄŸÃ¼" sayfasÄ±nda job gÃ¶rÃ¼nÃ¼r

---

**Son GÃ¼ncelleme**: 21 Ocak 2026
**Yazar**: Kiro AI Assistant
