# Crawler Sunucu Kurulum ve Sorun Giderme

## ğŸš¨ Crawler Ã‡alÄ±ÅŸmÄ±yor - Sorun Giderme AdÄ±mlarÄ±

### 1. Diagnostic Tool Ã‡alÄ±ÅŸtÄ±r

Sunucuya SSH ile baÄŸlan ve diagnostic tool'u Ã§alÄ±ÅŸtÄ±r:

```bash
cd /path/to/crwal4ai/admin_remix
python diagnostic.py
```

Bu tool ÅŸunlarÄ± kontrol eder:

- âœ… Python versiyonu
- âœ… Google Chrome kurulu mu
- âœ… Xvfb (virtual display) Ã§alÄ±ÅŸÄ±yor mu
- âœ… Python dependencies kurulu mu
- âœ… Database baÄŸlantÄ±sÄ± Ã§alÄ±ÅŸÄ±yor mu
- âœ… Dosya izinleri doÄŸru mu
- âœ… Crawler script syntax hatasÄ± var mÄ±

### 2. LoglarÄ± Kontrol Et

Crawler Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda 2 log dosyasÄ± oluÅŸur:

```bash
# STDOUT logu
cat /path/to/crwal4ai/admin_remix/crawler_debug.log

# STDERR logu (hatalar burada)
cat /path/to/crwal4ai/admin_remix/crawler_error.log
```

### 3. Manuel Test

Crawler'Ä± manuel olarak test et:

```bash
cd /path/to/crwal4ai/admin_remix
python sahibinden_uc_batch_supabase.py --categories konut_satilik --max-pages 1
```

EÄŸer hata alÄ±rsan, hatayÄ± not al ve dÃ¼zelt.

---

## ğŸ”§ YaygÄ±n Sorunlar ve Ã‡Ã¶zÃ¼mleri

### Sorun 1: Chrome BulunamadÄ±

**Hata:**

```
selenium.common.exceptions.WebDriverException: Message: unknown error: cannot find Chrome binary
```

**Ã‡Ã¶zÃ¼m:**

```bash
# Chrome kur
wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | gpg --dearmor -o /usr/share/keyrings/google-chrome.gpg
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome.gpg] http://dl.google.com/linux/chrome/deb/ stable main" > /etc/apt/sources.list.d/google-chrome.list
apt-get update
apt-get install -y google-chrome-stable

# Kontrol et
google-chrome --version
```

### Sorun 2: Display HatasÄ±

**Hata:**

```
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: exited abnormally
```

**Ã‡Ã¶zÃ¼m:**

```bash
# Xvfb kur
apt-get install -y xvfb

# Xvfb baÅŸlat
Xvfb :99 -screen 0 1920x1080x24 &

# DISPLAY deÄŸiÅŸkenini ayarla
export DISPLAY=:99

# Kontrol et
echo $DISPLAY
ps aux | grep Xvfb
```

### Sorun 3: Database BaÄŸlantÄ± HatasÄ±

**Hata:**

```
psycopg2.OperationalError: could not connect to server
```

**Ã‡Ã¶zÃ¼m:**

```bash
# .env dosyasÄ±nÄ± kontrol et
cat /path/to/crwal4ai/admin_remix/.env

# DATABASE_URL doÄŸru mu?
# DoÄŸru format:
# DATABASE_URL=postgres://postgres:518518Erkan@wgkosgwkg8o4wg4k8cgcw4og:5432/demir_db

# Database'e baÄŸlanabilir misin?
psql "postgres://postgres:518518Erkan@wgkosgwkg8o4wg4k8cgcw4og:5432/demir_db" -c "SELECT 1"
```

### Sorun 4: Python Dependencies Eksik

**Hata:**

```
ModuleNotFoundError: No module named 'undetected_chromedriver'
```

**Ã‡Ã¶zÃ¼m:**

```bash
cd /path/to/crwal4ai/admin_remix
pip install -r requirements.txt

# Veya tek tek:
pip install undetected-chromedriver selenium beautifulsoup4 psycopg2-binary flask python-dotenv
```

### Sorun 5: Dosya Ä°zin HatasÄ±

**Hata:**

```
PermissionError: [Errno 13] Permission denied: '/app/admin_remix/uc_chrome_profile'
```

**Ã‡Ã¶zÃ¼m:**

```bash
# Crawler klasÃ¶rÃ¼ne yazma izni ver
chmod -R 755 /path/to/crwal4ai/admin_remix
chown -R www-data:www-data /path/to/crwal4ai/admin_remix

# Veya Docker iÃ§inde:
chmod -R 777 /app/admin_remix/uc_chrome_profile
```

---

## ğŸ³ Docker Container Ä°Ã§inde Sorun Giderme

### Container'a Gir

```bash
# Container ID'yi bul
docker ps

# Container'a gir
docker exec -it <container_id> bash
```

### Diagnostic Tool Ã‡alÄ±ÅŸtÄ±r

```bash
cd /app/admin_remix
python diagnostic.py
```

### LoglarÄ± Ä°zle

```bash
# Flask app logu
docker logs -f <container_id>

# Crawler logu
docker exec -it <container_id> tail -f /app/admin_remix/crawler_debug.log
docker exec -it <container_id> tail -f /app/admin_remix/crawler_error.log
```

### Manuel Crawler Test

```bash
docker exec -it <container_id> bash
cd /app/admin_remix
export DISPLAY=:99
python sahibinden_uc_batch_supabase.py --categories konut_satilik --max-pages 1
```

---

## ğŸ“Š Mining Jobs Tablosunu Kontrol Et

Crawler job'larÄ± `mining_jobs` tablosunda saklanÄ±r:

```sql
-- Son 10 job'u gÃ¶ster
SELECT
    id,
    job_type,
    status,
    created_at,
    error
FROM mining_jobs
ORDER BY created_at DESC
LIMIT 10;

-- Failed job'larÄ±n hatalarÄ±nÄ± gÃ¶ster
SELECT
    id,
    created_at,
    error
FROM mining_jobs
WHERE status = 'failed'
ORDER BY created_at DESC
LIMIT 5;
```

---

## ğŸ”„ Crawler'Ä± Yeniden BaÅŸlat

### Docker Container'Ä± Yeniden BaÅŸlat

```bash
# Container'Ä± durdur
docker stop <container_id>

# Container'Ä± baÅŸlat
docker start <container_id>

# Veya yeniden build et
cd /path/to/crwal4ai
docker build -t crawler-app .
docker run -d -p 5001:5001 --name crawler crawler-app
```

### Coolify'da Yeniden Deploy

1. Coolify dashboard'a git
2. Crawler service'i bul
3. "Redeploy" butonuna tÄ±kla
4. LoglarÄ± izle

---

## ğŸ“ Ã–nemli Notlar

1. **Xvfb Mutlaka Ã‡alÄ±ÅŸmalÄ±**: Headless Chrome iÃ§in virtual display gerekli
2. **DISPLAY=:99**: Environment variable doÄŸru ayarlanmalÄ±
3. **Chrome Kurulu OlmalÄ±**: google-chrome-stable paketi kurulu olmalÄ±
4. **Database BaÄŸlantÄ±sÄ±**: Internal hostname kullan (wgkosgwkg8o4wg4k8cgcw4og:5432)
5. **Dosya Ä°zinleri**: Chrome profile klasÃ¶rÃ¼ne yazma izni olmalÄ±

---

## ğŸ†˜ Hala Ã‡alÄ±ÅŸmÄ±yor mu?

1. **Diagnostic tool Ã§Ä±ktÄ±sÄ±nÄ± kaydet**:

   ```bash
   python diagnostic.py > diagnostic_output.txt
   ```

2. **TÃ¼m loglarÄ± topla**:

   ```bash
   cat crawler_debug.log > all_logs.txt
   cat crawler_error.log >> all_logs.txt
   docker logs <container_id> >> all_logs.txt
   ```

3. **Database job'larÄ±nÄ± kontrol et**:

   ```sql
   SELECT * FROM mining_jobs ORDER BY created_at DESC LIMIT 5;
   ```

4. **Bu bilgileri Erkan'a gÃ¶nder** - sorun Ã§Ã¶zÃ¼lÃ¼r!

---

## âœ… BaÅŸarÄ±lÄ± Kurulum KontrolÃ¼

Crawler doÄŸru Ã§alÄ±ÅŸÄ±yorsa:

1. âœ… `python diagnostic.py` tÃ¼m kontrolleri geÃ§er
2. âœ… Manuel test baÅŸarÄ±lÄ± olur
3. âœ… `mining_jobs` tablosunda `status='completed'` gÃ¶rÃ¼nÃ¼r
4. âœ… `collected_listings` tablosuna yeni ilanlar eklenir
5. âœ… Admin panelde "Ä°ÅŸlem GÃ¼nlÃ¼ÄŸÃ¼" sayfasÄ±nda job gÃ¶rÃ¼nÃ¼r

---

**Son GÃ¼ncelleme**: 21 Ocak 2026
**Yazar**: Kiro AI Assistant

---

## ğŸ”¥ CLOUDFLARE 403 SORUNU (GÃœNCEL)

**Durum:** Sunucudan `curl` ile Sahibinden'e eriÅŸilemiyor (403 Forbidden)

```bash
curl -I https://www.sahibinden.com/satilik/sakarya-hendek
# HTTP/2 403
# server: cloudflare
```

**Neden:** Cloudflare, sunucu IP'sini bot olarak algÄ±lÄ±yor.

**Ã‡Ã¶zÃ¼m:** Chrome browser ile **gÃ¶rsel olarak** (headless deÄŸil) eriÅŸmek gerekiyor. Xvfb ile virtual display kullanÄ±yoruz.

### âœ… YapÄ±lan Ä°yileÅŸtirmeler (21 Ocak 2026)

1. **Chrome Options Optimize Edildi:**
   - Linux User-Agent (X11; Linux x86_64)
   - WebGL ve Canvas fingerprint eklendi
   - GerÃ§ek browser profili (languages, preferences)
   - Automation flags tamamen gizlendi

2. **Cloudflare Challenge Detection:**
   - "Checking your browser" mesajÄ± tespit ediliyor
   - Challenge Ã§Ã¶zÃ¼lene kadar bekliyor (max 30 saniye)
   - 403 durumunda hemen durduruluyor

3. **Rate Limiter YavaÅŸlatÄ±ldÄ±:**
   - Base delay: 4 saniye (Cloudflare iÃ§in gÃ¼venli)
   - Min delay: 2.5 saniye
   - Requests/minute: 20 (Ã§ok yavaÅŸ ama gÃ¼venli)

4. **CDP Commands ile Stealth:**
   - `navigator.webdriver` undefined
   - `navigator.plugins` dolu array
   - `window.chrome` object eklendi

### ğŸ§ª Test AdÄ±mlarÄ±

```bash
# 1. Xvfb Ã§alÄ±ÅŸÄ±yor mu?
ps aux | grep Xvfb
# Ã‡Ä±ktÄ±: Xvfb :99 -screen 0 1920x1080x24

# 2. DISPLAY ayarlÄ± mÄ±?
echo $DISPLAY
# Ã‡Ä±ktÄ±: :99

# 3. Chrome baÅŸlÄ±yor mu?
cd /app/admin_remix
python diagnostic.py
# âœ… Chrome found: /usr/bin/google-chrome
# âœ… Xvfb is running

# 4. Crawler test (1 sayfa)
python sahibinden_uc_batch_supabase.py --categories konut_satilik --max-pages 1

# Beklenen Ã§Ä±ktÄ±:
# ğŸš€ Chrome baÅŸlatÄ±lÄ±yor...
# âœ… Chrome hazÄ±r!
# ğŸŒ https://www.sahibinden.com/satilik/sakarya-hendek...
# â³ Cloudflare challenge tespit edildi, bekleniyor...
# âœ… Cloudflare challenge Ã§Ã¶zÃ¼ldÃ¼!
# âœ… 50 ilan iÅŸlendi, 5 yeni, 45 gÃ¼ncellendi
```

### ğŸš¨ Hala Block Yiyorsa

**SeÃ§enek 1: Daha YavaÅŸ Crawl**

```python
# sahibinden_uc_batch_supabase.py - satÄ±r ~240
self.rate_limiter = AdaptiveRateLimiter(
    RateLimiterConfig(
        base_delay=8.0,  # 4 -> 8 saniye (Ã‡OK YAVAÅ)
        min_delay=5.0,   # 2.5 -> 5 saniye
        requests_per_minute=10,  # 20 -> 10 istek/dakika
    )
)
```

**SeÃ§enek 2: Proxy Kullan**

```python
# sahibinden_uc_batch_supabase.py - _get_chrome_options() iÃ§inde
options.add_argument('--proxy-server=http://proxy-ip:port')
```

**SeÃ§enek 3: Residential Proxy Servisi**

- Bright Data, Oxylabs, Smartproxy gibi servisler
- TÃ¼rkiye IP'si kullan (Sahibinden TÃ¼rkiye sitesi)

**SeÃ§enek 4: VPN**

```bash
# Sunucuya VPN kur
apt install openvpn
# TÃ¼rkiye sunucusuna baÄŸlan
```

**SeÃ§enek 5: FarklÄ± Sunucu/IP**

- Hetzner yerine TÃ¼rkiye'deki bir VPS kullan
- Cloudflare TÃ¼rkiye IP'lerini daha az blokluyor
- Veya farklÄ± bir Hetzner datacenter dene

### ğŸ“Š Crawler Performans Beklentileri

**YavaÅŸ Mod (GÃ¼venli):**

- 20 istek/dakika = 3 saniye/sayfa
- 100 sayfa = ~5 dakika
- 1000 ilan = ~10 dakika

**Normal Mod:**

- 30 istek/dakika = 2 saniye/sayfa
- 100 sayfa = ~3.5 dakika

**Turbo Mod (RÄ°SKLÄ° - Block riski yÃ¼ksek):**

- 60 istek/dakika = 1 saniye/sayfa
- 100 sayfa = ~2 dakika

### ğŸ” Debug: Cloudflare Challenge GÃ¶rme

EÄŸer challenge'Ä± gÃ¶rmek istersen:

```bash
# VNC server kur (opsiyonel)
apt install x11vnc
x11vnc -display :99 -forever -nopw -listen 0.0.0.0 -xkb

# Lokal bilgisayardan baÄŸlan
# VNC Viewer: sunucu-ip:5900
# Chrome'un Cloudflare challenge'Ä± Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼ gÃ¶rebilirsin
```

---
