"""
Detail Queue Worker - Kuyruktan ilan detaylarÄ±nÄ± Ã§eker
========================================================
VeritabanÄ±ndaki listing_detail_queue tablosundan pending ilanlarÄ± alÄ±r,
detaylarÄ±nÄ± Ã§eker ve collected_listings tablosunu gÃ¼nceller.

KullanÄ±m:
    python detail_queue_worker.py
    python detail_queue_worker.py --limit 10
    python detail_queue_worker.py --continuous
"""

import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from bs4 import BeautifulSoup
import psycopg2
import time
import json
import random
import logging
import argparse
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Dosya yollarÄ±
SCRIPT_DIR = Path(__file__).parent
CHROME_PROFILE = SCRIPT_DIR / "uc_detail_profile"

# Supabase baÄŸlantÄ±
DB_URL = "postgres://postgres.cxeakfwtrlnjcjzvqdip:G8gDkqRVkzX8mEs8@aws-1-us-east-1.pooler.supabase.com:6543/postgres"

# Ayarlar
DELAY_MIN = 3
DELAY_MAX = 6

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:133.0) Gecko/20100101 Firefox/133.0",
]


class DetailQueueWorker:
    """Kuyruktan detay Ã§eken worker"""
    
    def __init__(self):
        self.driver = None
        self.conn = None
        self.stats = {
            "processed": 0,
            "success": 0,
            "failed": 0,
        }
    
    def connect_db(self):
        """VeritabanÄ±na baÄŸlan"""
        self.conn = psycopg2.connect(DB_URL)
        logger.info("âœ… VeritabanÄ±na baÄŸlandÄ±")
    
    def close_db(self):
        """VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± kapat"""
        if self.conn:
            self.conn.close()
    
    def start_browser(self):
        """Browser'Ä± baÅŸlat"""
        logger.info("ğŸš€ Chrome baÅŸlatÄ±lÄ±yor...")
        
        CHROME_PROFILE.mkdir(exist_ok=True)
        
        options = uc.ChromeOptions()
        options.add_argument(f'user-agent={random.choice(USER_AGENTS)}')
        options.add_argument(f"--window-size=1920,1080")
        options.add_argument(f'--user-data-dir={CHROME_PROFILE}')
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument('--no-sandbox')
        options.add_argument('--lang=tr-TR')
        
        self.driver = uc.Chrome(options=options)
        self.driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )
        
        logger.info("âœ… Chrome hazÄ±r!")
    
    def close_browser(self):
        """Browser'Ä± kapat"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass
    
    def get_pending_items(self, limit: int = 10) -> List[Dict]:
        """Kuyruktan pending itemlarÄ± al"""
        cur = self.conn.cursor()
        cur.execute("""
            SELECT id, listing_id, source_id, source_url, attempts
            FROM listing_detail_queue
            WHERE status = 'pending' AND attempts < max_attempts
            ORDER BY RANDOM()
            LIMIT %s
        """, (limit,))
        
        items = []
        for row in cur.fetchall():
            items.append({
                "queue_id": row[0],
                "listing_id": row[1],
                "source_id": row[2],
                "source_url": row[3],
                "attempts": row[4],
            })
        
        cur.close()
        return items
    
    def mark_processing(self, queue_id: str):
        """Item'Ä± processing olarak iÅŸaretle"""
        cur = self.conn.cursor()
        cur.execute("""
            UPDATE listing_detail_queue
            SET status = 'processing', started_at = NOW(), attempts = attempts + 1
            WHERE id = %s
        """, (queue_id,))
        self.conn.commit()
        cur.close()
    
    def mark_completed(self, queue_id: str):
        """Item'Ä± completed olarak iÅŸaretle"""
        cur = self.conn.cursor()
        cur.execute("""
            UPDATE listing_detail_queue
            SET status = 'completed', completed_at = NOW()
            WHERE id = %s
        """, (queue_id,))
        self.conn.commit()
        cur.close()
    
    def mark_failed(self, queue_id: str, error: str):
        """Item'Ä± failed olarak iÅŸaretle"""
        cur = self.conn.cursor()
        cur.execute("""
            UPDATE listing_detail_queue
            SET status = CASE WHEN attempts >= max_attempts THEN 'failed' ELSE 'pending' END,
                error_message = %s
            WHERE id = %s
        """, (error, queue_id))
        self.conn.commit()
        cur.close()
    
    def update_listing(self, listing_id: str, details: Dict):
        """Listing'i detaylarla gÃ¼ncelle"""
        cur = self.conn.cursor()
        cur.execute("""
            UPDATE collected_listings
            SET description = %s,
                features = %s,
                images = %s,
                area = %s,
                processed_at = NOW()
            WHERE id = %s
        """, (
            details.get("description"),
            json.dumps(details.get("features", {}), ensure_ascii=False),
            json.dumps(details.get("images", []), ensure_ascii=False),
            details.get("area"),
            listing_id
        ))
        self.conn.commit()
        cur.close()
    
    def _human_delay(self, min_s: float = 1, max_s: float = 3):
        """Ä°nsan benzeri bekleme"""
        time.sleep(random.uniform(min_s, max_s))
    
    def _wait_for_cloudflare(self, timeout: int = 60) -> bool:
        """Cloudflare bekle"""
        start = time.time()
        while time.time() - start < timeout:
            try:
                ps = self.driver.page_source.lower()
                if "classifieddetail" in ps or "classified-detail" in ps:
                    return True
                time.sleep(2)
            except:
                time.sleep(2)
        return False
    
    def extract_detail(self, url: str) -> Optional[Dict]:
        """Detay sayfasÄ±ndan bilgileri Ã§Ä±kar"""
        try:
            self.driver.get(url)
            self._human_delay(2, 4)
            
            if not self._wait_for_cloudflare():
                return None
            
            # Scroll
            self.driver.execute_script("window.scrollTo(0, 500);")
            self._human_delay(1, 2)
            
            html = self.driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            
            detail = {}
            
            # AÃ§Ä±klama
            desc_el = soup.select_one("#classifiedDescription")
            if desc_el:
                detail["description"] = desc_el.get_text(strip=True)
            
            # Ã–zellikler
            features = {}
            info_list = soup.select("ul.classifiedInfoList li")
            for li in info_list:
                label = li.select_one("strong")
                value = li.select_one("span")
                if label and value:
                    key = label.get_text(strip=True).replace(":", "")
                    val = value.get_text(strip=True)
                    features[key] = val
                    
                    # Alan bilgisi
                    if "mÂ²" in key.lower() or "brÃ¼t" in key.lower() or "net" in key.lower():
                        try:
                            area_val = int(''.join(filter(str.isdigit, val)))
                            if area_val > 0:
                                detail["area"] = area_val
                        except:
                            pass
            
            detail["features"] = features
            
            # Resimler
            images = []
            img_els = soup.select(".classifiedDetailMainPhoto img, .classifiedDetailPhotos img")
            for img in img_els:
                src = img.get("src") or img.get("data-src")
                if src and "shbdn.com" in src:
                    # BÃ¼yÃ¼k resim URL'i
                    big_src = src.replace("/lthmb_", "/x5_").replace("/thmb_", "/x5_")
                    if big_src not in images:
                        images.append(big_src)
            
            detail["images"] = images[:20]  # Max 20 resim
            
            logger.info(f"âœ… Detay Ã§ekildi: {len(detail.get('description', ''))} char, {len(features)} Ã¶zellik, {len(images)} resim")
            
            return detail
            
        except Exception as e:
            logger.error(f"âŒ Detay Ã§ekme hatasÄ±: {e}")
            return None
    
    def process_item(self, item: Dict) -> bool:
        """Tek bir item'Ä± iÅŸle"""
        queue_id = item["queue_id"]
        listing_id = item["listing_id"]
        source_id = item["source_id"]
        url = item["source_url"]
        
        logger.info(f"\nğŸ“„ Ä°ÅŸleniyor: {source_id}")
        logger.info(f"   URL: {url[:60]}...")
        
        self.mark_processing(queue_id)
        
        try:
            details = self.extract_detail(url)
            
            if details:
                self.update_listing(listing_id, details)
                self.mark_completed(queue_id)
                self.stats["success"] += 1
                return True
            else:
                self.mark_failed(queue_id, "Detail extraction failed")
                self.stats["failed"] += 1
                return False
                
        except Exception as e:
            self.mark_failed(queue_id, str(e))
            self.stats["failed"] += 1
            return False
        
        finally:
            self.stats["processed"] += 1
    
    def run(self, limit: int = 10, continuous: bool = False):
        """Worker'Ä± Ã§alÄ±ÅŸtÄ±r"""
        logger.info("=" * 60)
        logger.info("ğŸ”„ DETAIL QUEUE WORKER")
        logger.info("=" * 60)
        
        self.connect_db()
        self.start_browser()
        
        try:
            while True:
                items = self.get_pending_items(limit)
                
                if not items:
                    if continuous:
                        logger.info("â³ Kuyruk boÅŸ, 60 saniye bekleniyor...")
                        time.sleep(60)
                        continue
                    else:
                        logger.info("âœ… Kuyruk boÅŸ, Ã§Ä±kÄ±lÄ±yor")
                        break
                
                logger.info(f"\nğŸ“‹ {len(items)} item iÅŸlenecek")
                
                for item in items:
                    self.process_item(item)
                    
                    # Ä°lanlar arasÄ± bekleme
                    delay = random.uniform(DELAY_MIN, DELAY_MAX)
                    logger.info(f"â³ {delay:.1f} saniye bekleniyor...")
                    time.sleep(delay)
                
                if not continuous:
                    break
        
        except KeyboardInterrupt:
            logger.info("\nâ¸ï¸ KullanÄ±cÄ± tarafÄ±ndan durduruldu")
        
        finally:
            self.close_browser()
            self.close_db()
        
        # Ã–zet
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š Ã–ZET")
        logger.info("=" * 60)
        logger.info(f"   Ä°ÅŸlenen: {self.stats['processed']}")
        logger.info(f"   BaÅŸarÄ±lÄ±: {self.stats['success']}")
        logger.info(f"   BaÅŸarÄ±sÄ±z: {self.stats['failed']}")


def main():
    parser = argparse.ArgumentParser(description="Detail Queue Worker")
    parser.add_argument("--limit", type=int, default=10, help="Her seferde iÅŸlenecek item sayÄ±sÄ±")
    parser.add_argument("--continuous", action="store_true", help="SÃ¼rekli Ã§alÄ±ÅŸ")
    args = parser.parse_args()
    
    worker = DetailQueueWorker()
    worker.run(limit=args.limit, continuous=args.continuous)


if __name__ == "__main__":
    main()
