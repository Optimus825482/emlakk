"""
Crawler HÄ±zlÄ± Test
==================
Tek kategori, tek sayfa ile crawler'Ä± test eder.
"""

import sys
import os

# Script dizinini path'e ekle
sys.path.insert(0, os.path.dirname(__file__))

from sahibinden_uc_batch_supabase import SahibindenSupabaseCrawler, HENDEK_CATEGORIES
import logging

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

def test_crawler():
    """Crawler hÄ±zlÄ± test"""
    logger.info("ğŸš€ Crawler hÄ±zlÄ± test baÅŸlÄ±yor...")
    
    crawler = SahibindenSupabaseCrawler()
    
    try:
        # Browser baÅŸlat
        crawler.start_browser()
        
        # Tek kategori test et (konut_satilik)
        category_key = "konut_satilik"
        category_data = HENDEK_CATEGORIES[category_key]
        
        logger.info(f"ğŸ“‚ Test kategorisi: {category_key}")
        logger.info(f"ğŸŒ URL: {category_data['url']}")
        
        # Ä°lk sayfaya git
        html = crawler.navigate(category_data['url'])
        
        if html:
            logger.info("âœ… Sayfa baÅŸarÄ±yla yÃ¼klendi!")
            
            # Ä°lanlarÄ± Ã§Ä±kar
            listings = crawler.extract_listings(html)
            logger.info(f"ğŸ“Š {len(listings)} ilan bulundu")
            
            # Ä°lk 3 ilanÄ± gÃ¶ster
            for i, listing in enumerate(listings[:3], 1):
                logger.info(f"  {i}. {listing.get('baslik', 'N/A')[:50]}... - {listing.get('fiyat', 'N/A')}")
            
            logger.info("âœ… Test baÅŸarÄ±lÄ±!")
            return True
        else:
            logger.error("âŒ Sayfa yÃ¼klenemedi")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Test hatasÄ±: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False
        
    finally:
        # Temizlik
        crawler.close_browser()

if __name__ == "__main__":
    success = test_crawler()
    exit(0 if success else 1)
