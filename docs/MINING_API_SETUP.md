# Mining API Kurulum ve KullanÄ±m KÄ±lavuzu

## ğŸ¯ Genel BakÄ±ÅŸ

Mining API, Sahibinden.com crawler'larÄ±nÄ± kontrol etmek ve durumlarÄ±nÄ± takip etmek iÃ§in FastAPI tabanlÄ± bir backend servisidir.

## ğŸ“¦ Ã–zellikler

- âœ… Liste crawler (Supabase'e direkt yazma)
- âœ… Detay crawler (Supabase'e direkt yazma)
- âœ… Local crawler'lar (JSON output)
- âœ… Job yÃ¶netimi ve tracking
- âœ… Real-time log streaming
- âœ… Background task execution
- âœ… Rate limiting entegrasyonu

## ğŸš€ Kurulum

### 1. Mining API'yi BaÅŸlat

```bash
cd D:\demir\yy\demir-gayrimenkul\crwal4ai
uvicorn mining_api:app --host 0.0.0.0 --port 8765 --reload
```

**Port:** 8765 (crawler_api.py'den farklÄ±!)

### 2. Environment Variables

`.env` dosyasÄ±nda:

```env
SUPABASE_URL=https://cxeakfwtrlnjcjzvqdip.supabase.co
SUPABASE_SERVICE_KEY=your_service_key_here
SUPABASE_ANON_KEY=your_anon_key_here
```

### 3. Next.js Environment

`demir-gayrimenkul/.env.local`:

```env
MINING_API_URL=http://localhost:8765
```

## ğŸ“¡ API Endpoints

### Health Check

```bash
GET http://localhost:8765/health
```

**Response:**

```json
{
  "status": "healthy",
  "timestamp": "2026-01-19T08:50:00"
}
```

### Stats

```bash
GET http://localhost:8765/stats
```

**Response:**

```json
{
  "total_listings": 150,
  "active_jobs": 1,
  "recent_24h": 50,
  "pending_details": 30,
  "active_processes": 1,
  "by_category": {
    "konut": 100,
    "isyeri": 30,
    "arsa": 20
  }
}
```

### Start List Crawl

```bash
POST http://localhost:8765/jobs/list-crawl
Content-Type: application/json

{
  "categories": ["konut_satilik"],
  "max_pages": 5,
  "max_listings": null
}
```

**Response:**

```json
{
  "message": "Liste crawler baÅŸlatÄ±ldÄ±",
  "job_id": "uuid-here"
}
```

### Start Detail Crawl

```bash
POST http://localhost:8765/jobs/detail-crawl
Content-Type: application/json

{
  "max_listings": 50
}
```

### Get Job Status

```bash
GET http://localhost:8765/jobs/{job_id}
```

**Response:**

```json
{
  "job": {
    "id": "uuid",
    "job_type": "list_crawl",
    "source": "sahibinden",
    "status": "running",
    "progress": { "current": 3, "total": 5, "percentage": 60 },
    "stats": { "total_listings": 45 },
    "created_at": "2026-01-19T08:50:00",
    "started_at": "2026-01-19T08:50:05",
    "completed_at": null,
    "error_message": null
  },
  "logs": [
    {
      "id": "log-uuid",
      "job_id": "uuid",
      "level": "info",
      "message": "3. sayfa taranÄ±yor...",
      "created_at": "2026-01-19T08:50:15"
    }
  ]
}
```

### Cancel Job

```bash
POST http://localhost:8765/jobs/{job_id}/cancel
```

### List Jobs

```bash
GET http://localhost:8765/jobs?limit=20&status=running
```

### Get Logs

```bash
GET http://localhost:8765/jobs/{job_id}/logs?limit=50
```

### Stream Logs (Polling)

```bash
GET http://localhost:8765/logs/stream?job_id={job_id}&last_id={last_log_id}
```

## ğŸ”„ Next.js Entegrasyonu

### API Routes

TÃ¼m Next.js API route'larÄ± `mining_api.py`'ye yÃ¶nlendirildi:

1. **POST /api/crawler/crawl** â†’ `POST /jobs/list-crawl`
2. **GET /api/crawler/health** â†’ `GET /health`
3. **GET /api/crawler/jobs/[jobId]** â†’ `GET /jobs/{job_id}`

### Frontend KullanÄ±mÄ±

Admin panel: `http://localhost:3000/admin/veri-toplama`

```typescript
// Crawler baÅŸlat
const response = await fetch("/api/crawler/crawl", {
  method: "POST",
  body: JSON.stringify({
    url: "https://www.sahibinden.com/satilik-konut/sakarya-hendek",
    maxPages: 5,
    withDetails: false,
  }),
});

const { jobId } = await response.json();

// Job durumunu kontrol et
const jobResponse = await fetch(`/api/crawler/jobs/${jobId}`);
const job = await jobResponse.json();
```

## ğŸ—„ï¸ Database Schema

### mining_jobs

```sql
CREATE TABLE mining_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  job_type TEXT NOT NULL,  -- 'list_crawl', 'detail_crawl', etc.
  source TEXT NOT NULL,     -- 'sahibinden', 'emlakjet', etc.
  status TEXT NOT NULL,     -- 'pending', 'running', 'completed', 'failed', 'cancelled'
  config JSONB,
  progress JSONB,
  stats JSONB,
  error_message TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ,
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### mining_logs

```sql
CREATE TABLE mining_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  job_id UUID REFERENCES mining_jobs(id) ON DELETE CASCADE,
  level TEXT NOT NULL,  -- 'info', 'warning', 'error', 'success'
  message TEXT NOT NULL,
  data JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### sahibinden_liste

```sql
CREATE TABLE sahibinden_liste (
  id SERIAL PRIMARY KEY,
  ilan_no TEXT UNIQUE NOT NULL,
  baslik TEXT,
  fiyat TEXT,
  konum TEXT,
  tarih TEXT,
  link TEXT,
  resim TEXT,
  category TEXT,
  detay_cekildi BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

## ğŸ”§ Crawler Scripts

### Liste Crawler (Supabase)

```bash
python sahibinden_uc_batch_supabase.py \
  --categories konut_satilik \
  --max-pages 5 \
  --job-id uuid-here
```

**Ã–zellikler:**

- Supabase'e direkt yazma
- Duplicate detection
- Rate limiting
- Cloudflare bypass

### Detay Crawler (Supabase)

```bash
python sahibinden_uc_detail_supabase.py \
  --max-listings 50 \
  --job-id uuid-here
```

**Ã–zellikler:**

- Pending listelerden detay Ã§ekme
- Supabase'e direkt yazma
- Retry mechanism

### Local Crawler (JSON)

```bash
python sahibinden_uc_batch.py \
  --categories konut_satilik \
  --max-pages 5 \
  --job-id uuid-here
```

**Ã–zellikler:**

- JSON output
- Local file storage
- Test amaÃ§lÄ±

## âš ï¸ Ã–nemli Notlar

### Cloudflare Bypass

Ä°lk Ã§alÄ±ÅŸtÄ±rmada Chrome penceresi aÃ§Ä±lÄ±r ve manuel geÃ§iÅŸ gerekebilir:

1. Chrome penceresi aÃ§Ä±lÄ±r
2. Cloudflare challenge'Ä± manuel geÃ§
3. Crawler otomatik devam eder

### Rate Limiting

`rate_limiter.py` adaptive rate limiting kullanÄ±r:

- BaÅŸlangÄ±Ã§: 2-4 saniye delay
- Cloudflare block: Exponential backoff
- Success: Delay azalÄ±r

### Process Management

Mining API background process'leri yÃ¶netir:

- `active_processes` dict'te tracking
- Shutdown'da otomatik terminate
- Cancel endpoint ile manuel terminate

## ğŸ› Troubleshooting

### Mining API Ã§alÄ±ÅŸmÄ±yor

```bash
# Port kontrolÃ¼
netstat -ano | findstr :8765

# Logs kontrol
# Terminal'de uvicorn output'u kontrol et
```

### Crawler hata veriyor

```bash
# Job logs kontrol et
GET http://localhost:8765/jobs/{job_id}/logs

# Supabase connection kontrol et
# .env dosyasÄ±nda SUPABASE_SERVICE_KEY var mÄ±?
```

### Duplicate if **name** hatasÄ±

âœ… DÃ¼zeltildi! `sahibinden_uc_batch_supabase.py` dosyasÄ±nda sadece bir tane `if __name__ == "__main__":` bloÄŸu var.

## ğŸ“Š Monitoring

### Active Jobs

```bash
GET http://localhost:8765/jobs?status=running
```

### Recent Logs

```bash
GET http://localhost:8765/logs?limit=100&level=error
```

### Stats Dashboard

Admin panel: `http://localhost:3000/admin/veri-toplama`

## ğŸ”„ Workflow

1. **Start Mining API:** `uvicorn mining_api:app --port 8765 --reload`
2. **Open Admin Panel:** `http://localhost:3000/admin/veri-toplama`
3. **Start Crawler:** "TaramayÄ± BaÅŸlat" butonuna tÄ±kla
4. **Monitor:** Job durumunu ve loglarÄ± izle
5. **Check Results:** Supabase'de `sahibinden_liste` tablosunu kontrol et

## ğŸ“ Version History

- **v1.0.0** (19 Ocak 2026): Ä°lk release
  - Liste crawler entegrasyonu
  - Detay crawler entegrasyonu
  - Job management
  - Log streaming
  - Next.js API entegrasyonu
